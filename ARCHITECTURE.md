# System Architecture - Multi-Dataset Anomaly Detection

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        INPUT LAYER                                  â”‚
â”‚  Raw Log Files (.log, .txt, etc.)                                   â”‚
â”‚  â”œâ”€ Apache.log                                                      â”‚
â”‚  â”œâ”€ Nginx.log                                                       â”‚
â”‚  â”œâ”€ System.log                                                      â”‚
â”‚  â””â”€ Application.log                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PROCESSING LAYER (bert.py)                       â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  BERT Tokenization & Embedding Generation                 â”‚     â”‚
â”‚  â”‚  â”œâ”€ Tokenize log strings                                  â”‚     â”‚
â”‚  â”‚  â”œâ”€ Generate 768-dim vectors                              â”‚     â”‚
â”‚  â”‚  â””â”€ Mean pooling with attention mask                      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     STORAGE LAYER (.npy files)                      â”‚
â”‚  Embedding Files (NumPy Arrays)                                     â”‚
â”‚  â”œâ”€ apache_embeddings.npy      (Nâ‚ Ã— 768)                          â”‚
â”‚  â”œâ”€ nginx_embeddings.npy       (Nâ‚‚ Ã— 768)                          â”‚
â”‚  â”œâ”€ system_embeddings.npy      (Nâ‚ƒ Ã— 768)                          â”‚
â”‚  â””â”€ application_embeddings.npy (Nâ‚„ Ã— 768)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              VALIDATION LAYER (inspect_datasets.py)                 â”‚
â”‚  Optional: Validate & Compare Datasets                              â”‚
â”‚  â”œâ”€ Check dimensions                                                â”‚
â”‚  â”œâ”€ Calculate statistics                                            â”‚
â”‚  â”œâ”€ Compare datasets                                                â”‚
â”‚  â””â”€ Recommend cluster count                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ANALYSIS LAYER (kmeans.py)                             â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  LogAnomalyDetector Class                                 â”‚     â”‚
â”‚  â”‚                                                           â”‚     â”‚
â”‚  â”‚  1. Load Embeddings (*.npy)                              â”‚     â”‚
â”‚  â”‚     â”œâ”€ Single file                                        â”‚     â”‚
â”‚  â”‚     â”œâ”€ Multiple files                                     â”‚     â”‚
â”‚  â”‚     â””â”€ Glob patterns                                      â”‚     â”‚
â”‚  â”‚                                                           â”‚     â”‚
â”‚  â”‚  2. Combine Datasets                                      â”‚     â”‚
â”‚  â”‚     â””â”€ Vertical stack: (Nâ‚+Nâ‚‚+Nâ‚ƒ+Nâ‚„) Ã— 768              â”‚     â”‚
â”‚  â”‚                                                           â”‚     â”‚
â”‚  â”‚  3. Train KMeans Clustering                               â”‚     â”‚
â”‚  â”‚     â”œâ”€ Fit model on combined data                        â”‚     â”‚
â”‚  â”‚     â””â”€ Calculate cluster centers                          â”‚     â”‚
â”‚  â”‚                                                           â”‚     â”‚
â”‚  â”‚  4. Anomaly Detection                                     â”‚     â”‚
â”‚  â”‚     â”œâ”€ Transform new log to vector                       â”‚     â”‚
â”‚  â”‚     â”œâ”€ Assign to nearest cluster                         â”‚     â”‚
â”‚  â”‚     â”œâ”€ Calculate distance to center                      â”‚     â”‚
â”‚  â”‚     â””â”€ Compare with threshold                            â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      OUTPUT LAYER                                   â”‚
â”‚  Anomaly Detection Results                                          â”‚
â”‚  â”œâ”€ is_anomaly: Boolean                                             â”‚
â”‚  â”œâ”€ distance: Float (distance to cluster center)                    â”‚
â”‚  â”œâ”€ cluster_id: Integer (assigned cluster)                          â”‚
â”‚  â””â”€ threshold: Float (anomaly threshold)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Data Flow

### 1. Embedding Generation Phase (bert.py)

```
Raw Logs â†’ Tokenization â†’ BERT Model â†’ Mean Pooling â†’ .npy Files
  â†“            â†“              â†“             â†“             â†“
Text         Tokens        Hidden        Mean         Embeddings
Strings      (IDs)         States       Vector        (768-dim)
                          (768-dim)
```

### 2. Model Training Phase (kmeans.py)

```
.npy Files â†’ Load & Combine â†’ KMeans Training â†’ Trained Model
   â†“              â†“                  â†“                â†“
Multiple       Combined           Cluster          Model with
Datasets       Dataset            Centers          5 Clusters
(Nâ‚Ã—768)      (N_totalÃ—768)      (5Ã—768)
(Nâ‚‚Ã—768)
(Nâ‚ƒÃ—768)
```

### 3. Anomaly Detection Phase (kmeans.py)

```
New Log â†’ Transform â†’ Predict Cluster â†’ Calculate Distance â†’ Anomaly?
  â†“          â†“            â†“                    â†“                â†“
Text      Vector      Cluster ID           Distance         Boolean
String    (768-dim)     (0-4)              to Center        + Details
```

## ğŸ“Š Component Interaction Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ 1. Add log files
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    bert.py      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€ HuggingFace BERT Model
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ 2. Generate embeddings
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  .npy files      â”‚
â”‚  (Storage)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ 3. Validate (optional)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚inspect_datasets  â”‚
â”‚      .py         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ 4. Load & analyze
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   kmeans.py      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€ scikit-learn KMeans
â”‚(LogAnomalyDetector)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ 5. Detect anomalies
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Application    â”‚
â”‚  (Your Code)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Class Structure

### LogAnomalyDetector Class

```python
class LogAnomalyDetector:
    â”‚
    â”œâ”€ __init__(model_name)
    â”‚  â”œâ”€ Initialize BERT tokenizer
    â”‚  â”œâ”€ Initialize BERT model
    â”‚  â””â”€ Set up class attributes
    â”‚
    â”œâ”€ transform_log_to_vector(log_text)
    â”‚  â”œâ”€ Input:  str (raw log)
    â”‚  â”œâ”€ Process: BERT embedding
    â”‚  â””â”€ Output: np.array (768,)
    â”‚
    â”œâ”€ transform_logs_to_vectors(log_texts)
    â”‚  â”œâ”€ Input:  List[str] (multiple logs)
    â”‚  â”œâ”€ Process: Batch BERT embedding
    â”‚  â””â”€ Output: np.array (N, 768)
    â”‚
    â”œâ”€ load_embeddings(embedding_files)
    â”‚  â”œâ”€ Input:  str or List[str] (file paths or patterns)
    â”‚  â”œâ”€ Process: Load and combine .npy files
    â”‚  â””â”€ Output: np.array (N_total, 768)
    â”‚
    â”œâ”€ train_kmeans(n_clusters, random_state)
    â”‚  â”œâ”€ Input:  int (number of clusters)
    â”‚  â”œâ”€ Process: Train KMeans on embeddings
    â”‚  â””â”€ Output: KMeans model
    â”‚
    â””â”€ predict_anomaly(log_text, threshold_percentile)
       â”œâ”€ Input:  str (log to check)
       â”œâ”€ Process: Transform â†’ Predict â†’ Calculate distance
       â””â”€ Output: (bool, float, int, float)
                  (is_anomaly, distance, cluster_id, threshold)
```

## ğŸ”§ Configuration Points

### 1. BERT Model Configuration (kmeans.py)

```python
detector = LogAnomalyDetector(model_name="bert-base-uncased")
# Can be changed to other BERT models:
# - "bert-large-uncased"
# - "distilbert-base-uncased" (faster)
# - Any HuggingFace BERT model
```

### 2. KMeans Configuration (kmeans.py)

```python
detector.train_kmeans(
    n_clusters=5,      # Number of clusters (adjust based on data)
    random_state=42    # For reproducibility
)
```

### 3. Anomaly Threshold Configuration (kmeans.py)

```python
detector.predict_anomaly(
    log_text,
    threshold_percentile=95  # Top 5% are anomalies
    # Can be 90 (top 10%), 99 (top 1%), etc.
)
```

### 4. Log File Processing (bert.py)

```python
log_files = [
    r"..\dataset\Apache.log",
    r"..\dataset\Nginx.log",
    # Add more files here
]
```

## ï¿½ï¿½ Scalability Considerations

### Memory Usage

```
Single Embedding:    768 Ã— 4 bytes = 3.072 KB (float32)
1,000 Embeddings:    768 Ã— 4 Ã— 1,000 = 3.072 MB
10,000 Embeddings:   768 Ã— 4 Ã— 10,000 = 30.72 MB
100,000 Embeddings:  768 Ã— 4 Ã— 100,000 = 307.2 MB
1M Embeddings:       768 Ã— 4 Ã— 1,000,000 = 3.072 GB
```

### Processing Time

```
BERT Embedding:      ~10-50ms per log (GPU)
                     ~50-200ms per log (CPU)

KMeans Training:     O(n Ã— k Ã— i Ã— d)
                     n = samples, k = clusters
                     i = iterations, d = dimensions
                     ~seconds to minutes for typical datasets
```

## ğŸ” Security Considerations

1. **Environment Variables**: BERT authentication via account.env
2. **Data Privacy**: Embeddings stored locally, not shared
3. **Input Validation**: Error handling for malformed logs
4. **File Access**: Read-only access to log files

## ğŸ§ª Testing Strategy

### Unit Tests (Recommended)

```python
# Test log transformation
def test_transform_log():
    detector = LogAnomalyDetector()
    vector = detector.transform_log_to_vector("Test log")
    assert vector.shape == (768,)

# Test dataset loading
def test_load_embeddings():
    detector = LogAnomalyDetector()
    detector.load_embeddings('*.npy')
    assert detector.embeddings is not None

# Test anomaly detection
def test_predict_anomaly():
    detector = LogAnomalyDetector()
    detector.load_embeddings('*.npy')
    detector.train_kmeans(n_clusters=3)
    is_anomaly, _, _, _ = detector.predict_anomaly("Test")
    assert isinstance(is_anomaly, bool)
```

## ğŸ“Š Performance Optimization Tips

1. **Batch Processing**: Use `transform_logs_to_vectors()` for multiple logs
2. **GPU Acceleration**: Enable CUDA for faster BERT inference
3. **Model Caching**: BERT model loads once and reuses
4. **Memory Management**: Use `torch.no_grad()` during inference
5. **Parallel Processing**: Process multiple log files in parallel

## ğŸ“ Advanced Use Cases

### 1. Real-Time Monitoring

```python
detector = LogAnomalyDetector()
detector.load_embeddings('historical_*.npy')
detector.train_kmeans(n_clusters=5)

# Monitor incoming logs
for log in incoming_log_stream():
    is_anomaly, dist, cluster, threshold = detector.predict_anomaly(log)
    if is_anomaly:
        alert_system.send_alert(log, dist, cluster)
```

### 2. Batch Analysis

```python
# Analyze all logs from a time period
logs = load_logs_from_period("2024-01-01", "2024-01-31")
vectors = detector.transform_logs_to_vectors(logs)
# Save for later analysis
np.save("january_embeddings.npy", vectors)
```

### 3. Incremental Learning

```python
# Train on historical data
detector.load_embeddings('historical_*.npy')
detector.train_kmeans(n_clusters=5)

# Periodically retrain with new data
new_embeddings = detector.transform_logs_to_vectors(new_logs)
combined = np.vstack([detector.embeddings, new_embeddings])
detector.embeddings = combined
detector.train_kmeans(n_clusters=5)
```

---

**Architecture Status**: âœ… Production-Ready  
**Documentation**: âœ… Complete  
**Maintainability**: âœ… High
